
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import random
import argparse
import sys


#sys.path.append('/Users/Charles/Documents/Github/tensorflow/')
#print(sys.path)
from tensorflow.examples.tutorials.mnist import input_data

import tensorflow as tf 
import matplotlib.pyplot as plt
import numpy as np

FLAGS = None
def plotMatrix(matrix,r,c,subplot = 1):

	fig = plt.figure()
	ax = fig.add_subplot(1, 1, 1)

	#(r,c) = matrix.shape
	x = []
	y = []
	color = []
	for i in range(r):
		for k in range(c):
			index = i * r + k 
			x.append(k)
			y.append(r - i)
			color.append(matrix[index])
	rgb = plt.get_cmap('jet')(color)

	ax.scatter(x, y, color = rgb)
	plt.show()

def activationFunction(x,theta):
	z  = np.dot(x, theta)
	g = 1 / (1 + np.exp(-z)) #sigmoid function
	#g_deriv = np.multiply(g ,(1-g))
	return( g )#, g_deriv)  

def costFunction(g,y,m,theta,_lambda):
	J = - (1 / m) *  np.sum( np.multiply(y , np.log(g) ) + np.multiply( (1 - y), np.log(1-g)) )
	J +=  ((_lambda / (2 * m)) * np.sum(np.square(theta)) )
	return(J)

def train(theta,g,x,y,m,a,_lambda):
	(r,c) = theta.shape
	delta = np.zeros((r,c))
	#print(y)
	for i in range(m):
		exampleY = y[i]
		exampleX = x[i]
		exampleG = g[i]
		sigma = exampleG - exampleY # error 
		# print("example y:")
		# print(exampleY)
		# print("example G:")
		# print(exampleG)
		# print("sigma:")
		# print(sigma)
		delta += np.dot( np.transpose(exampleX) , sigma ) 
		
	# preventing the bias unit from being regularized
	thetatemp = theta 
	thetatemp[0,:] = 0
	delta =   a * (1 / m) * ( delta + _lambda * thetatemp) 
	theta = theta - delta 

	return(theta)

#function declartion for main function
def main(_):

	print('begin')



	mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)

	#for i in range(100):
	m = 1000# of training data per training step
	a =  1  # learning rate
	_lambda = 0.01
	training_steps = 55
	batchx , batchy =  mnist.train.next_batch( m ) # x is 784 for  a 28x28 image y is
	matx = np.matrix(batchx)


	# exampleX = matx[0,:]
	# plotMatrix(exampleX,28,28)


	maty = np.matrix(batchy)
	one = np.ones((m,1))
	matx = np.hstack((one,matx))
	num_features = matx.shape[1]
	num_output = maty.shape[1]
	print("Number of features: %d Number of Output: %d"%(num_features,num_output))
	#Creating the theta vector
	theta = np.random.rand(num_features, num_output)  / 1000
	print(theta[0:10,0:10])
	# print(theta.shape)
	# print(matx.shape)
	print("test cost")
	g = activationFunction(matx,theta)

	J = costFunction(g,maty,m,theta,_lambda)
	print(J)
	for i in range(training_steps):
		matx , maty =  mnist.train.next_batch( m ) # x is 784 for  a 28x28 image y is
		matx = np.matrix(batchx) 
		maty = np.matrix(batchy)
		one = np.ones((m,1))
		matx = np.hstack((one,matx))	
		g = activationFunction(matx,theta)
		#atemp =  a / ( a + 2 * (i / training_steps) )  
		theta = train(theta,g,matx,maty,m,a,_lambda)
		J = costFunction(g,maty,m,theta,_lambda)

		#print(J) #check if algorithm is working 

	#accuracy
	num_test = 1000
	batchx , batchy =  mnist.test.next_batch( num_test ) # x is 784 for  a 28x28 image y is
	matx = np.matrix(batchx) 
	maty = np.matrix(batchy)
	one = np.ones((num_test,1))
	matx = np.hstack((one,matx))
	g = activationFunction(matx,theta)
	prediction = np.zeros((num_test,1))
	actual = np.zeros((num_test,1))
	for i in range(len(g)):
		x = g[i]
		idx = np.where(x==x.max())[1]
		if len(idx) > 1:
			idx = idx[0]
		prediction[i] = idx
		#print(idx)
		y = maty[i]
		idx = np.where(y==y.max())[1]
		actual[i] = idx


 	comparison = np.hstack((actual,prediction))
	#print(actual)

	#print(prediction)
	error =  actual == prediction
	#print(error)
	accuracy = np.mean(error)
	print(accuracy)

	print(theta.shape)

	print(comparison[0:10])
	theta = theta * 1000
	print("Bias unit %d")
	print(theta[0,:])
	print("Other units")
	#print(theta[:,0])
	theta = np.transpose(theta)[0,1:]
	plotMatrix(theta,28,28,6)





	#mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
	#  55,000 training data mnist.train 10,000 test data mnist.test 5,000 validation data mnist.validation 
	# mnist.train.labels has the labels 0-9 of the training data


if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',
                      help='Directory for storing input data')
  FLAGS, unparsed = parser.parse_known_args()
  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
